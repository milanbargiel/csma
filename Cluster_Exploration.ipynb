{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cluster Exploration.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "cFvmIujCbs0S"
      ],
      "authorship_tag": "ABX9TyMPkUzKThUzRSt7ELpix8Ff",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/milanbargiel/csma/blob/main/Cluster_Exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXq2eF_D2_c5"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "In this notebook we perform Methods for making Sense of the Cluster Data.\n",
        "\n",
        "Therefore we will preprocess the data and then print for Cluster x:\n",
        "\n",
        "- Top 10 most frequently used word\n",
        "- Word Cloud\n",
        "- Topic Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihuYF97giMPe"
      },
      "source": [
        "# Install Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxvgitBdiQ7P",
        "outputId": "5541e212-2a5f-49c9-8fe7-2952d4720dda"
      },
      "source": [
        "!pip install fasttext\n",
        "!pip install contractions"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.7/dist-packages (0.9.2)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (54.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext) (1.19.5)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.7/dist-packages (from fasttext) (2.6.2)\n",
            "Requirement already satisfied: contractions in /usr/local/lib/python3.7/dist-packages (0.0.48)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.7/dist-packages (from contractions) (0.0.21)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (0.1.7)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PITtP8b_YfO1"
      },
      "source": [
        "# Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKfYqLK-Yk_g",
        "outputId": "b98e859f-e6fb-44ea-d8f8-cf9a48da3650"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "# packages for data preperation\n",
        "import nltk\n",
        "import string\n",
        "import fasttext\n",
        "import contractions\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "# download missing libraries\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYsvzwynYptt"
      },
      "source": [
        "# Set pandas printing options to improve readability\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.options.mode.chained_assignment = None\n",
        "pd.set_option('display.max_colwidth', 100)"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzIMp8p33j2g"
      },
      "source": [
        "# Import clusters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SW4WsYlYHGg",
        "outputId": "a338ec8e-ca1a-4c38-b54f-85325c4ae8a1"
      },
      "source": [
        "!python --version"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.7.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAtz74VfYEnU",
        "outputId": "f0bd4c3f-7ea6-424a-e85b-0c954d039f0f"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P822z0lRYWZG"
      },
      "source": [
        "input_path = \"/content/drive/My Drive/CSMA/Data/Clusters/grouped_by_year/\""
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "oxxrepboYyG3",
        "outputId": "5661a8e2-af44-4f7c-d1cf-35a242d3dc1c"
      },
      "source": [
        "data = pd.read_pickle(input_path+'/data_clustered_2020'+'.pkl')\n",
        "data = data.sort_values(by=['label_kmedoids'], ascending=False)\n",
        "data.head()"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>publishedAt</th>\n",
              "      <th>authorName</th>\n",
              "      <th>text</th>\n",
              "      <th>isReply</th>\n",
              "      <th>video_id</th>\n",
              "      <th>cleaned</th>\n",
              "      <th>label_manual</th>\n",
              "      <th>label_kmedoids</th>\n",
              "      <th>distance_kmedoids</th>\n",
              "      <th>highlight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6426</th>\n",
              "      <td>29903</td>\n",
              "      <td>2020-07-28 00:46:33</td>\n",
              "      <td>Cody</td>\n",
              "      <td>@Elyjah Stark During this plandemic, it's nice that they geoengineers have scaled back their wea...</td>\n",
              "      <td>1</td>\n",
              "      <td>wpSRp_R0J9A</td>\n",
              "      <td>@ During this plandemic, it's nice that they geoengineers have scaled back their weather manipul...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>51</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11775</th>\n",
              "      <td>53832</td>\n",
              "      <td>2020-11-27 06:16:46</td>\n",
              "      <td>Matt</td>\n",
              "      <td>@Vnimaniye I'd check out the US senate bill 517 of the 109th Congress (\"the weather modification...</td>\n",
              "      <td>1</td>\n",
              "      <td>b1Enrzgrl1w</td>\n",
              "      <td>@ I'd check out the US senate bill 517 of the 109th Congress (\"the weather modification and deve...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>51</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11778</th>\n",
              "      <td>53835</td>\n",
              "      <td>2020-11-25 12:52:56</td>\n",
              "      <td>Vnimaniye</td>\n",
              "      <td>You can manipulate weather and climate</td>\n",
              "      <td>1</td>\n",
              "      <td>b1Enrzgrl1w</td>\n",
              "      <td>You can manipulate weather and climate</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>51</td>\n",
              "      <td>0.000053</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11789</th>\n",
              "      <td>53846</td>\n",
              "      <td>2020-11-09 05:26:25</td>\n",
              "      <td>perf b</td>\n",
              "      <td>we have been unintentionally geoengineering for 100 years, time to get intentional about it, ass...</td>\n",
              "      <td>0</td>\n",
              "      <td>b1Enrzgrl1w</td>\n",
              "      <td>we have been unintentionally geoengineering for 100 years, time to get intentional about it, ass...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>51</td>\n",
              "      <td>0.000054</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11793</th>\n",
              "      <td>53850</td>\n",
              "      <td>2020-11-08 11:35:20</td>\n",
              "      <td>Slaterdom</td>\n",
              "      <td>I have 10years of photos and videos documenting the change in the skys. the already massive geoe...</td>\n",
              "      <td>0</td>\n",
              "      <td>b1Enrzgrl1w</td>\n",
              "      <td>I have 10years of photos and videos documenting the change in the skys. the already massive geoe...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>51</td>\n",
              "      <td>0.000080</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0          publishedAt authorName  \\\n",
              "6426        29903  2020-07-28 00:46:33       Cody   \n",
              "11775       53832  2020-11-27 06:16:46       Matt   \n",
              "11778       53835  2020-11-25 12:52:56  Vnimaniye   \n",
              "11789       53846  2020-11-09 05:26:25     perf b   \n",
              "11793       53850  2020-11-08 11:35:20  Slaterdom   \n",
              "\n",
              "                                                                                                      text  \\\n",
              "6426   @Elyjah Stark During this plandemic, it's nice that they geoengineers have scaled back their wea...   \n",
              "11775  @Vnimaniye I'd check out the US senate bill 517 of the 109th Congress (\"the weather modification...   \n",
              "11778                                                               You can manipulate weather and climate   \n",
              "11789  we have been unintentionally geoengineering for 100 years, time to get intentional about it, ass...   \n",
              "11793  I have 10years of photos and videos documenting the change in the skys. the already massive geoe...   \n",
              "\n",
              "       isReply     video_id  \\\n",
              "6426         1  wpSRp_R0J9A   \n",
              "11775        1  b1Enrzgrl1w   \n",
              "11778        1  b1Enrzgrl1w   \n",
              "11789        0  b1Enrzgrl1w   \n",
              "11793        0  b1Enrzgrl1w   \n",
              "\n",
              "                                                                                                   cleaned  \\\n",
              "6426   @ During this plandemic, it's nice that they geoengineers have scaled back their weather manipul...   \n",
              "11775  @ I'd check out the US senate bill 517 of the 109th Congress (\"the weather modification and deve...   \n",
              "11778                                                             You can manipulate weather and climate     \n",
              "11789  we have been unintentionally geoengineering for 100 years, time to get intentional about it, ass...   \n",
              "11793  I have 10years of photos and videos documenting the change in the skys. the already massive geoe...   \n",
              "\n",
              "       label_manual label_kmedoids  distance_kmedoids  highlight  \n",
              "6426           -1.0             51           0.000032        0.0  \n",
              "11775          -1.0             51           0.000064        0.0  \n",
              "11778          -1.0             51           0.000053        0.0  \n",
              "11789          -1.0             51           0.000054        0.0  \n",
              "11793          -1.0             51           0.000080        0.0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwDIkrjrdp1H"
      },
      "source": [
        "# Select a cluster"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zu3cf1dQdtUw",
        "outputId": "a8c0402d-3363-4a1d-c657-18051e32566c"
      },
      "source": [
        "# Choose a cluster\n",
        "cluster_number =   12\n",
        "data['label_kmedoids'] = data['label_kmedoids'].astype('category')\n",
        "cluster = data[data['label_kmedoids']==cluster_number]\n",
        "cluster.head()"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>publishedAt</th>\n",
              "      <th>authorName</th>\n",
              "      <th>text</th>\n",
              "      <th>isReply</th>\n",
              "      <th>video_id</th>\n",
              "      <th>cleaned</th>\n",
              "      <th>label_manual</th>\n",
              "      <th>label_kmedoids</th>\n",
              "      <th>distance_kmedoids</th>\n",
              "      <th>highlight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13400</th>\n",
              "      <td>55548</td>\n",
              "      <td>2020-01-02 16:29:45</td>\n",
              "      <td>amorag59</td>\n",
              "      <td>Sinister To see if it works 😂</td>\n",
              "      <td>1</td>\n",
              "      <td>1hhzrormtP4</td>\n",
              "      <td>Sinister To see if it works 😂</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>12</td>\n",
              "      <td>0.000047</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11854</th>\n",
              "      <td>53911</td>\n",
              "      <td>2020-11-02 15:13:33</td>\n",
              "      <td>LOOKUP2</td>\n",
              "      <td>Only Jesus Acts 4:12</td>\n",
              "      <td>1</td>\n",
              "      <td>b1Enrzgrl1w</td>\n",
              "      <td>Only Jesus Acts 4:12</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>12</td>\n",
              "      <td>0.000101</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6083</th>\n",
              "      <td>29543</td>\n",
              "      <td>2020-02-18 04:32:43</td>\n",
              "      <td>Helen Johnson- Tyus</td>\n",
              "      <td>@siouxperb5570 LOLOLOLOL!!!! LOLOLOL!!!! LOLOLOL!!!!</td>\n",
              "      <td>1</td>\n",
              "      <td>wpSRp_R0J9A</td>\n",
              "      <td>@ LOLOLOLOL!!!! LOLOLOL!!!! LOLOLOL!!!!</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>12</td>\n",
              "      <td>0.000107</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11851</th>\n",
              "      <td>53908</td>\n",
              "      <td>2020-11-01 14:49:40</td>\n",
              "      <td>Bartlemy</td>\n",
              "      <td>They&amp;#39;recreating the fkn CC !</td>\n",
              "      <td>0</td>\n",
              "      <td>b1Enrzgrl1w</td>\n",
              "      <td>They'recreating the fkn CC !</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>12</td>\n",
              "      <td>0.000089</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6253</th>\n",
              "      <td>29713</td>\n",
              "      <td>2020-01-31 22:04:01</td>\n",
              "      <td>Gary Larocca</td>\n",
              "      <td>Lol. Narcissists lol.</td>\n",
              "      <td>0</td>\n",
              "      <td>wpSRp_R0J9A</td>\n",
              "      <td>Lol. Narcissists lol.</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>12</td>\n",
              "      <td>0.000062</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0          publishedAt           authorName  \\\n",
              "13400       55548  2020-01-02 16:29:45             amorag59   \n",
              "11854       53911  2020-11-02 15:13:33              LOOKUP2   \n",
              "6083        29543  2020-02-18 04:32:43  Helen Johnson- Tyus   \n",
              "11851       53908  2020-11-01 14:49:40             Bartlemy   \n",
              "6253        29713  2020-01-31 22:04:01         Gary Larocca   \n",
              "\n",
              "                                                       text  isReply  \\\n",
              "13400                         Sinister To see if it works 😂        1   \n",
              "11854                                  Only Jesus Acts 4:12        1   \n",
              "6083   @siouxperb5570 LOLOLOLOL!!!! LOLOLOL!!!! LOLOLOL!!!!        1   \n",
              "11851                      They&#39;recreating the fkn CC !        0   \n",
              "6253                                  Lol. Narcissists lol.        0   \n",
              "\n",
              "          video_id                                    cleaned  label_manual  \\\n",
              "13400  1hhzrormtP4            Sinister To see if it works 😂            -1.0   \n",
              "11854  b1Enrzgrl1w                     Only Jesus Acts 4:12            -1.0   \n",
              "6083   wpSRp_R0J9A  @ LOLOLOLOL!!!! LOLOLOL!!!! LOLOLOL!!!!            -1.0   \n",
              "11851  b1Enrzgrl1w             They'recreating the fkn CC !            -1.0   \n",
              "6253   wpSRp_R0J9A                    Lol. Narcissists lol.            -1.0   \n",
              "\n",
              "      label_kmedoids  distance_kmedoids  highlight  \n",
              "13400             12           0.000047        0.0  \n",
              "11854             12           0.000101        0.0  \n",
              "6083              12           0.000107        0.0  \n",
              "11851             12           0.000089        0.0  \n",
              "6253              12           0.000062        0.0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jK0dMs51dXhe"
      },
      "source": [
        "# Data Preperation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "id": "Xh3t8YxWdbVM",
        "outputId": "d4d9719f-e6bf-4945-ddb9-e0fc3dfd9ea4"
      },
      "source": [
        "# Merge all comments of a cluster into one\n",
        "cluster_merged = {'text': ''}\n",
        "\n",
        "for index, row in cluster.iterrows():\n",
        "  cluster_merged['text'] += row['cleaned']\n",
        "\n",
        "# Create dataframe out of dictionary\n",
        "cdf = pd.DataFrame(cluster_merged, index=[0])\n",
        "\n",
        "# Do data preperation\n",
        "# 1. Expand Contractions (We would'nt -> We would not)\n",
        "cdf['no_contract'] = cdf['text'].apply(lambda x:[contractions.fix(word) for word in x.split()])\n",
        "cdf['text_str'] = [' '.join(map(str, l)) for l in cdf['no_contract']] # Detokenize\n",
        "\n",
        "# 2. Tokenization\n",
        "cdf['tokenized'] = cdf['text_str'].apply(word_tokenize)\n",
        "\n",
        "#3. Convert to lower case\n",
        "cdf['lower'] = cdf['tokenized'].apply(lambda x: [word.lower() for word in x])\n",
        "\n",
        "#4. Removing punctuation\n",
        "punc = string.punctuation\n",
        "cdf['no_punc'] = cdf['lower'].apply(lambda x: [word for word in x if word not in punc])\n",
        "\n",
        "#5. Removing stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "cdf['stopwords_removed'] = cdf['no_punc'].apply(lambda x: [word for word in x if word not in stop_words])\n",
        "\n",
        "#6. Lemmatization\n",
        "# Apply part of speech tags: Determine the part of speech (ie. noun, verb, adverb, etc.) for each word.\n",
        "cdf['pos_tags'] = cdf['stopwords_removed'].apply(nltk.tag.pos_tag)\n",
        "\n",
        "# Convert to wordnet pos for NLTK’s word lemmatizer\n",
        "def get_wordnet_pos(tag):\n",
        "    if tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN\n",
        "\n",
        "cdf['wordnet_pos'] = cdf['pos_tags'].apply(lambda x: [(word, get_wordnet_pos(pos_tag)) for (word, pos_tag) in x])\n",
        "\n",
        "# Apply NLTK’s word lemmatizer\n",
        "wnl = WordNetLemmatizer()\n",
        "cdf['lemmatized'] = cdf['wordnet_pos'].apply(lambda x: [wnl.lemmatize(word, tag) for word, tag in x])\n",
        "cdf.head()"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>no_contract</th>\n",
              "      <th>text_str</th>\n",
              "      <th>tokenized</th>\n",
              "      <th>lower</th>\n",
              "      <th>no_punc</th>\n",
              "      <th>stopwords_removed</th>\n",
              "      <th>pos_tags</th>\n",
              "      <th>wordnet_pos</th>\n",
              "      <th>lemmatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sinister To see if it works 😂  Only Jesus Acts 4:12  @ LOLOLOLOL!!!! LOLOLOL!!!! LOLOLOL!!!!  Th...</td>\n",
              "      <td>[Sinister, To, see, if, it, works, 😂, Only, Jesus, Acts, 4:12, @, LOLOLOLOL!!!!, LOLOLOL!!!!, LO...</td>\n",
              "      <td>Sinister To see if it works 😂 Only Jesus Acts 4:12 @ LOLOLOLOL!!!! LOLOLOL!!!! LOLOLOL!!!! They'...</td>\n",
              "      <td>[Sinister, To, see, if, it, works, 😂, Only, Jesus, Acts, 4:12, @, LOLOLOLOL, !, !, !, !, LOLOLOL...</td>\n",
              "      <td>[sinister, to, see, if, it, works, 😂, only, jesus, acts, 4:12, @, lolololol, !, !, !, !, lololol...</td>\n",
              "      <td>[sinister, to, see, if, it, works, 😂, only, jesus, acts, 4:12, lolololol, lololol, lololol, they...</td>\n",
              "      <td>[sinister, see, works, 😂, jesus, acts, 4:12, lolololol, lololol, lololol, they'recreating, fkn, ...</td>\n",
              "      <td>[(sinister, NN), (see, VBP), (works, VBZ), (😂, NNP), (jesus, NN), (acts, VBZ), (4:12, CD), (lolo...</td>\n",
              "      <td>[(sinister, n), (see, v), (works, v), (😂, n), (jesus, n), (acts, v), (4:12, n), (lolololol, n), ...</td>\n",
              "      <td>[sinister, see, work, 😂, jesus, act, 4:12, lolololol, lololol, lololol, they'recreating, fkn, cc...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                  text  \\\n",
              "0  Sinister To see if it works 😂  Only Jesus Acts 4:12  @ LOLOLOLOL!!!! LOLOLOL!!!! LOLOLOL!!!!  Th...   \n",
              "\n",
              "                                                                                           no_contract  \\\n",
              "0  [Sinister, To, see, if, it, works, 😂, Only, Jesus, Acts, 4:12, @, LOLOLOLOL!!!!, LOLOLOL!!!!, LO...   \n",
              "\n",
              "                                                                                              text_str  \\\n",
              "0  Sinister To see if it works 😂 Only Jesus Acts 4:12 @ LOLOLOLOL!!!! LOLOLOL!!!! LOLOLOL!!!! They'...   \n",
              "\n",
              "                                                                                             tokenized  \\\n",
              "0  [Sinister, To, see, if, it, works, 😂, Only, Jesus, Acts, 4:12, @, LOLOLOLOL, !, !, !, !, LOLOLOL...   \n",
              "\n",
              "                                                                                                 lower  \\\n",
              "0  [sinister, to, see, if, it, works, 😂, only, jesus, acts, 4:12, @, lolololol, !, !, !, !, lololol...   \n",
              "\n",
              "                                                                                               no_punc  \\\n",
              "0  [sinister, to, see, if, it, works, 😂, only, jesus, acts, 4:12, lolololol, lololol, lololol, they...   \n",
              "\n",
              "                                                                                     stopwords_removed  \\\n",
              "0  [sinister, see, works, 😂, jesus, acts, 4:12, lolololol, lololol, lololol, they'recreating, fkn, ...   \n",
              "\n",
              "                                                                                              pos_tags  \\\n",
              "0  [(sinister, NN), (see, VBP), (works, VBZ), (😂, NNP), (jesus, NN), (acts, VBZ), (4:12, CD), (lolo...   \n",
              "\n",
              "                                                                                           wordnet_pos  \\\n",
              "0  [(sinister, n), (see, v), (works, v), (😂, n), (jesus, n), (acts, v), (4:12, n), (lolololol, n), ...   \n",
              "\n",
              "                                                                                            lemmatized  \n",
              "0  [sinister, see, work, 😂, jesus, act, 4:12, lolololol, lololol, lololol, they'recreating, fkn, cc...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    }
  ]
}